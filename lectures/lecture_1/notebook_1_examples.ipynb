{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03bc9012",
   "metadata": {},
   "source": [
    "# Лекция 1: Примеры NLP на русском языке (spaCy)\n",
    "\n",
    "В этом ноутбуке показаны 3 задачи:\n",
    "\n",
    "1. Определение смысла слова (по контексту)\n",
    "2. Анализ эмоционального окраса\n",
    "3. Распознавание именованных сущностей (NER)\n",
    "\n",
    "Во всех шагах используются русские примеры и короткая проверка результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f79e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка библиотек (выполнить один раз)\n",
    "!pip install -q spacy\n",
    "!python -m spacy download ru_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac0160a-6747-4e81-9646-52491d3243b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv run python -m spacy download ru_core_news_md # TODO: Only for uv users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62636c2-8ec1-48a5-b164-d32f1bceefb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/spacy/ru_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6601ad11-0f5e-4e5f-9301-71f9904b575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ru_core_news_sm — меньше и быстрее, но слабее\n",
    "# ru_core_news_lg — больше и точнее, но тяжелее\n",
    "# ru_core_news_md - баланс точности и скорости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300694b3",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Модель загружена: core_news_md\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_md\")\n",
    "print(\"Модель загружена:\", nlp.meta.get(\"name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bee2b5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c37027d",
   "metadata": {},
   "source": [
    "# Задача: Определение смысла слова\n",
    "## Как работает (по какому принципу, словари и т.п.)\n",
    "Один из простых подходов: сравнивать контекст предложения с «эталонными» описаниями смыслов.\n",
    "Вместо ручных словарей можно использовать векторные представления текста (эмбеддинги spaCy) и выбирать смысл с максимальным сходством."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b21ccc43",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Предложение: Я добавил лук в суп.\n",
      "Оценки похожести: {'оружие': 0.5074542145680851, 'овощ': 0.571432042899425}\n",
      "Предсказанный смысл слова 'лук': овощ\n"
     ]
    }
   ],
   "source": [
    "## Пример кода, который это делает\n",
    "target_word = \"лук\"\n",
    "\n",
    "sense_examples = {\n",
    "    \"оружие\": \"Лучник натянул тетиву и выстрелил из лука в цель.\",\n",
    "    \"овощ\": \"Для салата нужен свежий зеленый лук и укроп.\"\n",
    "}\n",
    "\n",
    "sentence = \"Я добавил лук в суп.\"\n",
    "context_doc = nlp(sentence)\n",
    "\n",
    "scores = {}\n",
    "for sense, example in sense_examples.items():\n",
    "    scores[sense] = context_doc.similarity(nlp(example))\n",
    "\n",
    "predicted_sense = max(scores, key=scores.get)\n",
    "\n",
    "print(\"Предложение:\", sentence)\n",
    "print(\"Оценки похожести:\", scores)\n",
    "print(\"Предсказанный смысл слова '\", target_word, \"': \", predicted_sense, sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902b9c58",
   "metadata": {},
   "source": [
    "## Пояснение к выполнению\n",
    "- Мы описали два значения слова `лук` через примеры.\n",
    "- Считаем сходство контекста предложения с каждым примером.\n",
    "- Значение с наибольшим сходством принимаем как наиболее вероятное."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac47d9b",
   "metadata": {},
   "source": [
    "## Как работает `similarity` в spaCy\n",
    "\n",
    "`Doc.similarity(other_doc)` сравнивает векторные представления двух текстов.\n",
    "- у каждого слова есть вектор (числовое представление смысла),\n",
    "- для предложения берется усредненный вектор,\n",
    "- затем считается косинусная близость между векторами (значение от -1 до 1) (поговорим о расстояниях позже)\n",
    "\n",
    "Чем выше число, тем ближе тексты по смыслу.\n",
    "\n",
    "### Простенький подход (без сложных моделей)\n",
    "Можно сравнивать не векторы, а пересечение лемм:\n",
    "- нормализуем слова через spaCy (`lemma_`),\n",
    "- убираем стоп-слова,\n",
    "- считаем долю общих лемм.\n",
    "\n",
    "Такой метод проще, но хуже понимает синонимы и скрытый контекст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6f3d1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример 1\n",
      "A: Я купил зеленый лук\n",
      "B: В салат добавили лук и укроп\n",
      "  spaCy similarity: 0.538\n",
      "  overlap лемм:     0.167\n",
      "--------------------------------------------------\n",
      "Пример 2\n",
      "A: Лук нарезали для супа\n",
      "B: Овощи отправили в кастрюлю\n",
      "  spaCy similarity: 0.212\n",
      "  overlap лемм:     0.000\n",
      "--------------------------------------------------\n",
      "Пример 3\n",
      "A: Лучник натянул лук\n",
      "B: Лучник выстрелил стрелой в цель\n",
      "  spaCy similarity: 0.147\n",
      "  overlap лемм:     0.167\n",
      "--------------------------------------------------\n",
      "Пример 4\n",
      "A: В магазине купили овощи\n",
      "B: На стадионе начался матч\n",
      "  spaCy similarity: 0.022\n",
      "  overlap лемм:     0.000\n",
      "--------------------------------------------------\n",
      "Пример 5\n",
      "A: Мне понравился этот фильм\n",
      "B: Картина произвела на меня хорошее впечатление\n",
      "  spaCy similarity: 0.525\n",
      "  overlap лемм:     0.000\n",
      "--------------------------------------------------\n",
      "Принцип сравнения:\n",
      "- similarity лучше ловит общий смысл;\n",
      "- overlap лемм лучше показывает буквальные совпадения слов.\n"
     ]
    }
   ],
   "source": [
    "## Примеры для сравнения\n",
    "\n",
    "def lemma_set(text: str):\n",
    "    doc = nlp(text)\n",
    "    return {t.lemma_.lower() for t in doc if t.is_alpha and not t.is_stop}\n",
    "\n",
    "def overlap_score(a: str, b: str) -> float:\n",
    "    a_set, b_set = lemma_set(a), lemma_set(b)\n",
    "\n",
    "    # a_set & b_set: пересечение (общие леммы)\n",
    "    # a_set | b_set: объединение (все уникальные леммы из обоих текстов)\n",
    "    \n",
    "    return len(a_set & b_set) / len(a_set | b_set)\n",
    "\n",
    "examples = [\n",
    "    # 1) Лексическое совпадение\n",
    "    (\"Я купил зеленый лук\", \"В салат добавили лук и укроп\"),\n",
    "    # 2) Контекст предметной области\n",
    "    (\"Лук нарезали для супа\", \"Овощи отправили в кастрюлю\"),\n",
    "    # 3) Другой смысл слова\n",
    "    (\"Лучник натянул лук\", \"Лучник выстрелил стрелой в цель\"),\n",
    "    # 4) Слабое тематическое совпадение\n",
    "    (\"В магазине купили овощи\", \"На стадионе начался матч\"),\n",
    "    # 5) Почти одинаковый смысл разными словами\n",
    "    (\"Мне понравился этот фильм\", \"Картина произвела на меня хорошее впечатление\"),\n",
    "]\n",
    "\n",
    "for i, (a, b) in enumerate(examples, 1):\n",
    "    vec_sim = nlp(a).similarity(nlp(b))\n",
    "    lex_sim = overlap_score(a, b)\n",
    "    print(f\"Пример {i}\")\n",
    "    print(\"A:\", a)\n",
    "    print(\"B:\", b)\n",
    "    print(f\"  spaCy similarity: {vec_sim:.3f}\")\n",
    "    print(f\"  overlap лемм:     {lex_sim:.3f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"Принцип сравнения:\")\n",
    "print(\"- similarity лучше ловит общий смысл;\")\n",
    "print(\"- overlap лемм лучше показывает буквальные совпадения слов.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd89c90a",
   "metadata": {},
   "source": [
    "# Задача: Анализ эмоционального окраса\n",
    "## Как работает (по какому принципу, словари и т.п.)\n",
    "Базовый подход: словарь положительных и отрицательных слов.\n",
    "spaCy помогает нормализовать слова (лемматизация), чтобы сравнение шло по начальной форме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "604bbe8e",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Текст: Мне очень понравился фильм, он был прекрасный и интересный.\n",
      "Леммы: ['мне', 'очень', 'понравиться', 'фильм', 'он', 'быть', 'прекрасный', 'и', 'интересный']\n",
      "Позитивных: 1 | Негативных: 0\n",
      "Эмоциональная окраска: позитивная\n"
     ]
    }
   ],
   "source": [
    "## Пример кода, который это делает\n",
    "positive_lemmas = {\"отличный\", \"радость\", \"счастливый\", \"прекрасный\", \"любить\"}\n",
    "negative_lemmas = {\"плохой\", \"грусть\", \"ужасный\", \"ненавидеть\", \"печальный\"}\n",
    "\n",
    "text = \"Мне очень понравился фильм, он был прекрасный и интересный.\"\n",
    "doc = nlp(text)\n",
    "lemmas = [t.lemma_.lower() for t in doc if t.is_alpha]\n",
    "\n",
    "pos_count = sum(1 for l in lemmas if l in positive_lemmas)\n",
    "neg_count = sum(1 for l in lemmas if l in negative_lemmas)\n",
    "\n",
    "if pos_count > neg_count:\n",
    "    sentiment = \"позитивная\"\n",
    "elif neg_count > pos_count:\n",
    "    sentiment = \"негативная\"\n",
    "else:\n",
    "    sentiment = \"нейтральная\"\n",
    "\n",
    "print(\"Текст:\", text)\n",
    "print(\"Леммы:\", lemmas)\n",
    "print(\"Позитивных:\", pos_count, \"| Негативных:\", neg_count)\n",
    "print(\"Эмоциональная окраска:\", sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ba97c",
   "metadata": {},
   "source": [
    "## Пояснение к выполнению\n",
    "- Сначала получаем леммы русского текста.\n",
    "- Затем считаем совпадения с позитивным и негативным словарями.\n",
    "- По балансу совпадений определяем итоговую эмоциональную окраску.\n",
    "- Для более высокой точности обычно используют обученные модели (например, ruBERT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff71358",
   "metadata": {},
   "source": [
    "# Задача: Распознавание именованных сущностей\n",
    "## Как работает (по какому принципу, словари и т.п.)\n",
    "NER-модель spaCy определяет в тексте сущности: людей, организации, локации и т.д.\n",
    "Модель обучена на размеченных корпусах, где сущности выделены заранее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187a05cd-6ef0-48b9-b1d2-e39ffc12b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://data-light.ru/blog/named-entity-recognition/#:~:text=NER%20(Named%20Entity%20Recognition%2C%20распознавание,Эти%20категории%20называются%20именованными%20сущностями.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21ba522",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Текст: Иван Петров работает в компании Яндекс в Москве.\n",
      "Найденные сущности:\n",
      "- Иван Петров -> PER\n",
      "- Яндекс -> ORG\n",
      "- Москве -> LOC\n"
     ]
    }
   ],
   "source": [
    "## Пример кода, который это делает\n",
    "text = \"Иван Петров работает в компании Яндекс в Москве.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "print(\"Текст:\", text)\n",
    "print(\"Найденные сущности:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"- {ent.text} -> {ent.label_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9577bfa4",
   "metadata": {},
   "source": [
    "## Пояснение к выполнению\n",
    "- Передаем русский текст в модель `ru_core_news_md`.\n",
    "- `doc.ents` возвращает найденные сущности.\n",
    "- Для проверки шага достаточно убедиться, что модель выделила имя, организацию и географическое место."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e39798f",
   "metadata": {},
   "source": [
    "## Проверка шагов\n",
    "Если при запуске возникают ошибки:\n",
    "1. Проверьте, что выполнились команды установки `!pip install ...`.\n",
    "2. Проверьте загрузку модели: `python -m spacy download ru_core_news_md`.\n",
    "3. Запускайте ячейки сверху вниз по порядку.\n",
    "\n",
    "После этого все примеры должны работать на русском языке."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
