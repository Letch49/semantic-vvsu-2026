# Задача 1: Лингвистика и синтаксический разбор текстовых данных

## Описание задачи

В данной задаче вам предстоит выполнить лингвистический анализ текстовых данных с использованием библиотек для синтаксического разбора (`natasha`, `spacy` или `nltk`) и морфологического анализа (`pymorphy3` или `spacy`). 

### Цель задачи

Найти в текстах **подлежащие и сказуемые**, построить зависимость их совместных употреблений и визуализировать результаты.

## Датасет
Использовать датасет собранных новостей, оставшийся с прошлого семестра (либо найти на kaggle)

### Что нужно сделать

1. **Загрузить текстовые данные** из предоставленного файла
2. **Разделить каждое предложение** на подлежащее и сказуемое
3. **Найти подлежащие и сказуемые** в каждом предложении (например, "студент учится", "преподаватель объясняет")
4. **Построить зависимости совместных употреблений**:
   - Какие подлежащие сочетаются с какими сказуемыми
   - Подсчитать частоту таких сочетаний
5. **Визуализировать результаты** (графики, таблицы, диаграммы)

### Технические требования

#### Разрешенные библиотеки:
- `pandas` - для загрузки файлов.
- Для синтаксического разбора (выберите одну или несколько):
  - `natasha` - для русского языка (синтаксический разбор и извлечение зависимостей)
  - `spacy` - для русского и английского языков (синтаксический разбор с поддержкой русского через модель `ru_core_news_sm`)
  - `nltk` - для английского языка (синтаксический разбор и парсинг)
- Для морфологического анализа:
- `pymorphy3` - для русского языка (морфологический анализ)
  - `spacy` - для русского и английского языков (морфологический анализ)
- `collections.Counter` - для подсчета частот (подсказка!)
- Стандартные библиотеки Python (json, re, и т.д.)
- Библиотеки для визуализации (matplotlib, seaborn, pandas)

#### Что нужно реализовать:

1. **Функцию для синтаксического разбора**
   - Использование `natasha`, `spacy` или `nltk` для получения синтаксических зависимостей
   - Выделение подлежащего и сказуемого в каждом предложении
   - Для русского языка рекомендуется `natasha` или `spacy` с моделью `ru_core_news_sm`
   - Для английского языка можно использовать `spacy` или `nltk`

2. **Функцию для построения зависимостей совместных употреблений**
   - Создание пар (подлежащее, сказуемое)
   - Подсчет частот с помощью `collections.Counter`
   - Сохранение результатов в удобном формате

4. **Функцию для визуализации**
   - Построение графиков частот
   - Визуализация наиболее частых сочетаний
   - Любые другие визуализации, которые помогут понять данные

### Критерии оценки (10 баллов)

- **2 балла**: Корректная загрузка и обработка текстовых данных
- **4 балла**: Правильное выделение подлежащих и сказуемых с использованием natasha или других библиотек для синтаксического разбора
- **3 балла**: Построение зависимостей совместных употреблений и подсчет частот
- **1 балл**: Качественная визуализация результатов

### Формат сдачи

1. Файл `task1-solution.ipynb` с решением задачи
2. Файл `report.md` с описанием:
   - Подхода к решению задачи
   - Объяснением полученных результатов
   - Выводами о закономерностях в данных

### Полезные ссылки

- [Документация Natasha](https://github.com/natasha/natasha) - для русского языка
- [Документация spaCy](https://spacy.io/) - для русского и английского языков
- [Документация NLTK](https://www.nltk.org/) - для английского языка
- [Документация PyMorphy3](https://pymorphy3.readthedocs.io/) - для русского языка
- [Документация collections.Counter](https://docs.python.org/3/library/collections.html#collections.Counter)

### Примеры ожидаемых результатов

После выполнения задачи вы должны получить:
- Список наиболее частых сочетаний до 100 с сортировкой по убыванию (подлежащее, сказуемое)
- Визуализации, показывающие распределение частот
- Анализ закономерностей в употреблении подлежащих и сказуемых

### Вопросы для размышления

Какие лингвистические закономерности можно выявить в данных?
