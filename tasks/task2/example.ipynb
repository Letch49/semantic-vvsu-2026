{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Задача 2: Нейронные сети и анализ тональности\n",
        "\n",
        "Примеры использования Keras для понимания задачи и проверки результатов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Импорт необходимых библиотек"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Пример: Анализ тональности текстов\n",
        "\n",
        "Основная задача - анализ тональности текстовых отзывов. Сначала подготовим данные и векторизуем тексты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Пример данных для анализа тональности (отзывы)\n",
        "sentiment_data = {\n",
        "    'text': [\n",
        "        # Положительные отзывы\n",
        "        'Отличный фильм, очень понравился!',\n",
        "        'Прекрасная книга, рекомендую всем прочитать.',\n",
        "        'Качественный товар, доволен покупкой.',\n",
        "        'Замечательный сервис, быстро и профессионально.',\n",
        "        'Потрясающий ресторан, вкусная еда и уютная атмосфера.',\n",
        "        'Великолепный спектакль, получил массу удовольствия.',\n",
        "        'Отличное приложение, удобный интерфейс.',\n",
        "        'Прекрасный отель, комфортные номера и хороший завтрак.',\n",
        "        'Замечательный преподаватель, интересные лекции.',\n",
        "        'Потрясающая музыка, слушаю постоянно.',\n",
        "        'Отличный телефон, все работает быстро.',\n",
        "        'Прекрасный подарок, очень доволен.',\n",
        "        'Качественный кофе, ароматный и вкусный.',\n",
        "        'Замечательный парк, красивая природа.',\n",
        "        'Потрясающий концерт, незабываемые эмоции.',\n",
        "        \n",
        "        # Отрицательные отзывы\n",
        "        'Ужасный фильм, полная потеря времени.',\n",
        "        'Плохая книга, скучно и неинтересно.',\n",
        "        'Низкое качество товара, очень разочарован.',\n",
        "        'Плохой сервис, долго ждал и ничего не получил.',\n",
        "        'Отвратительный ресторан, невкусная еда.',\n",
        "        'Скучный спектакль, не рекомендую.',\n",
        "        'Плохое приложение, постоянно глючит.',\n",
        "        'Ужасный отель, грязные номера и плохое обслуживание.',\n",
        "        'Скучный преподаватель, неинтересные лекции.',\n",
        "        'Плохая музыка, не понравилась.',\n",
        "        'Плохой телефон, постоянно зависает.',\n",
        "        'Разочаровался в подарке, не то что ожидал.',\n",
        "        'Плохой кофе, безвкусный и холодный.',\n",
        "        'Запущенный парк, грязно и неухоженно.',\n",
        "        'Скучный концерт, не оправдал ожиданий.',\n",
        "        \n",
        "        # Нейтральные отзывы (для мультиклассовой классификации)\n",
        "        'Обычный фильм, ничего особенного.',\n",
        "        'Стандартная книга, читается нормально.',\n",
        "        'Обычный товар, соответствует описанию.',\n",
        "        'Нормальный сервис, без особых претензий.',\n",
        "        'Обычный ресторан, стандартное меню.',\n",
        "        'Средний спектакль, можно посмотреть.',\n",
        "        'Обычное приложение, работает как надо.',\n",
        "        'Стандартный отель, без изысков.',\n",
        "        'Обычный преподаватель, стандартные лекции.',\n",
        "        'Средняя музыка, ничего особенного.',\n",
        "    ],\n",
        "    'sentiment': [\n",
        "        # Положительные (1)\n",
        "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "        # Отрицательные (0)\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        # Нейтральные (2)\n",
        "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "    ]\n",
        "}\n",
        "\n",
        "df_sentiment = pd.DataFrame(sentiment_data)\n",
        "print(f\\\"Всего отзывов: {len(df_sentiment)}\\\")\n",
        "print(f\\\"Распределение тональности:\\\")\n",
        "print(df_sentiment['sentiment'].value_counts().sort_index())\n",
        "print(\\\"\\\\nПримеры отзывов:\\\")\n",
        "print(df_sentiment.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Векторизация текстов для анализа тональности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Векторизация текстов с помощью TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=100, stop_words=None, ngram_range=(1, 2))\n",
        "X_sentiment = vectorizer.fit_transform(df_sentiment['text']).toarray()\n",
        "y_sentiment = df_sentiment['sentiment'].values\n",
        "\n",
        "print(f\\\"Размерность векторизованных данных: {X_sentiment.shape}\\\")\n",
        "print(f\\\"Количество признаков (слов и биграмм): {X_sentiment.shape[1]}\\\")\n",
        "\n",
        "# Разделение на train/test\n",
        "X_train_sent, X_test_sent, y_train_sent, y_test_sent = train_test_split(\n",
        "    X_sentiment, y_sentiment, test_size=0.3, random_state=42, stratify=y_sentiment\n",
        ")\n",
        "\n",
        "# Нормализация (опционально, но часто помогает)\n",
        "scaler_sent = StandardScaler()\n",
        "X_train_sent_scaled = scaler_sent.fit_transform(X_train_sent)\n",
        "X_test_sent_scaled = scaler_sent.transform(X_test_sent)\n",
        "\n",
        "print(f\\\"\\\\nОбучающая выборка: {X_train_sent_scaled.shape}\\\")\n",
        "print(f\\\"Тестовая выборка: {X_test_sent_scaled.shape}\\\")\n",
        "print(f\\\"Классы в обучающей выборке: {np.unique(y_train_sent, return_counts=True)}\\\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Пример: Бинарная классификация тональности (положительная/отрицательная)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Фильтруем только положительные и отрицательные отзывы (бинарная классификация)\n",
        "mask_binary = (y_train_sent != 2) & (y_test_sent != 2)\n",
        "X_train_bin_sent = X_train_sent_scaled[y_train_sent != 2]\n",
        "y_train_bin_sent = y_train_sent[y_train_sent != 2]\n",
        "X_test_bin_sent = X_test_sent_scaled[y_test_sent != 2]\n",
        "y_test_bin_sent = y_test_sent[y_test_sent != 2]\n",
        "\n",
        "print(f\\\"Бинарная классификация: {len(X_train_bin_sent)} обучающих, {len(X_test_bin_sent)} тестовых\\\")\n",
        "print(f\\\"Классы: {np.unique(y_train_bin_sent)}\\\")\n",
        "\n",
        "# Модель для бинарной классификации тональности\n",
        "model_sentiment_binary = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_bin_sent.shape[1],)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(1, activation='sigmoid')  # Бинарная классификация\n",
        "])\n",
        "\n",
        "model_sentiment_binary.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',  # Logloss для бинарной классификации\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stopping_sent = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Обучение\n",
        "history_sent_binary = model_sentiment_binary.fit(\n",
        "    X_train_bin_sent, y_train_bin_sent,\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping_sent],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Предсказания\n",
        "y_pred_sent_binary = (model_sentiment_binary.predict(X_test_bin_sent) > 0.5).astype(int).flatten()\n",
        "y_pred_proba_sent_binary = model_sentiment_binary.predict(X_test_bin_sent).flatten()\n",
        "\n",
        "# Метрики\n",
        "print(\\\"\\\\nМетрики для анализа тональности (бинарная классификация):\\\")\n",
        "print(f\\\"F1-score: {f1_score(y_test_bin_sent, y_pred_sent_binary):.4f}\\\")\n",
        "print(f\\\"Precision: {precision_score(y_test_bin_sent, y_pred_sent_binary):.4f}\\\")\n",
        "print(f\\\"Recall: {recall_score(y_test_bin_sent, y_pred_sent_binary):.4f}\\\")\n",
        "\n",
        "# Примеры предсказаний\n",
        "print(\\\"\\\\nПримеры предсказаний:\\\")\n",
        "test_texts = df_sentiment.loc[y_test_sent != 2, 'text'].values[:5]\n",
        "for i, text in enumerate(test_texts[:5]):\n",
        "    print(f\\\"\\\\nТекст: {text}\\\")\n",
        "    print(f\\\"Истинная тональность: {'Положительная' if y_test_bin_sent[i] == 1 else 'Отрицательная'}\\\")\n",
        "    print(f\\\"Предсказанная тональность: {'Положительная' if y_pred_sent_binary[i] == 1 else 'Отрицательная'}\\\")\n",
        "    print(f\\\"Вероятность положительной: {y_pred_proba_sent_binary[i]:.4f}\\\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Пример: Мультиклассовая классификация тональности (положительная/отрицательная/нейтральная)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Пример: Регрессия - предсказание рейтинга отзывов (0-10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Данные для регрессии рейтингов\n",
        "# Создаем рейтинги от 0 до 10 на основе тех же текстов\n",
        "rating_data = {\n",
        "    'text': df_sentiment['text'].tolist(),\n",
        "    'rating': [\n",
        "        # Положительные отзывы - высокие рейтинги (7-10)\n",
        "        9, 8, 9, 8, 10, 9, 8, 9, 8, 9, 8, 9, 8, 9, 10,\n",
        "        # Отрицательные отзывы - низкие рейтинги (0-3)\n",
        "        1, 2, 1, 2, 0, 1, 2, 0, 1, 2, 1, 2, 1, 2, 0,\n",
        "        # Нейтральные отзывы - средние рейтинги (4-6)\n",
        "        5, 6, 5, 6, 5, 6, 5, 6, 5, 6,\n",
        "    ]\n",
        "}\n",
        "\n",
        "df_rating = pd.DataFrame(rating_data)\n",
        "print(f\\\"Всего отзывов с рейтингами: {len(df_rating)}\\\")\n",
        "print(f\\\"Диапазон рейтингов: [{df_rating['rating'].min()}, {df_rating['rating'].max()}]\\\")\n",
        "print(f\\\"Средний рейтинг: {df_rating['rating'].mean():.2f}\\\")\n",
        "print(f\\\"Распределение рейтингов:\\\")\n",
        "print(df_rating['rating'].value_counts().sort_index())\n",
        "\n",
        "# Векторизация текстов (используем тот же vectorizer или создаем новый)\n",
        "vectorizer_rating = TfidfVectorizer(max_features=100, stop_words=None, ngram_range=(1, 2))\n",
        "X_rating = vectorizer_rating.fit_transform(df_rating['text']).toarray()\n",
        "y_rating = df_rating['rating'].values.astype(float)\n",
        "\n",
        "# Разделение на train/test\n",
        "X_train_rating, X_test_rating, y_train_rating, y_test_rating = train_test_split(\n",
        "    X_rating, y_rating, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Нормализация признаков\n",
        "scaler_rating = StandardScaler()\n",
        "X_train_rating_scaled = scaler_rating.fit_transform(X_train_rating)\n",
        "X_test_rating_scaled = scaler_rating.transform(X_test_rating)\n",
        "\n",
        "# Нормализация рейтингов (от 0 до 10 -> от 0 до 1 для лучшей сходимости)\n",
        "y_train_rating_scaled = y_train_rating / 10.0\n",
        "y_test_rating_scaled = y_test_rating / 10.0\n",
        "\n",
        "print(f\\\"\\\\nОбучающая выборка: {X_train_rating_scaled.shape}\\\")\n",
        "print(f\\\"Тестовая выборка: {X_test_rating_scaled.shape}\\\")\n",
        "print(f\\\"Диапазон рейтингов в обучающей выборке: [{y_train_rating.min():.1f}, {y_train_rating.max():.1f}]\\\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Модель для регрессии рейтингов\n",
        "model_rating = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_rating_scaled.shape[1],)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(1, activation='sigmoid')  # Sigmoid для ограничения выхода от 0 до 1\n",
        "])\n",
        "\n",
        "# Компиляция\n",
        "model_rating.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',  # Mean Squared Error для регрессии\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stopping_rating = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Обучение\n",
        "history_rating = model_rating.fit(\n",
        "    X_train_rating_scaled, y_train_rating_scaled,\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping_rating],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Предсказания (обратная нормализация: умножаем на 10 и ограничиваем от 0 до 10)\n",
        "y_pred_rating_scaled = model_rating.predict(X_test_rating_scaled).flatten()\n",
        "y_pred_rating = np.clip(y_pred_rating_scaled * 10.0, 0, 10)\n",
        "\n",
        "# Метрики для регрессии рейтингов\n",
        "mae_rating = mean_absolute_error(y_test_rating, y_pred_rating)\n",
        "rmse_rating = np.sqrt(mean_squared_error(y_test_rating, y_pred_rating))\n",
        "mape_rating = np.mean(np.abs((y_test_rating - y_pred_rating) / (y_test_rating + 1e-8))) * 100  # +1e-8 чтобы избежать деления на 0\n",
        "\n",
        "print(\\\"\\\\nМетрики для регрессии рейтингов:\\\")\n",
        "print(f\\\"MAE: {mae_rating:.4f} (средняя ошибка в баллах)\\\")\n",
        "print(f\\\"RMSE: {rmse_rating:.4f} (корень из средней квадратичной ошибки)\\\")\n",
        "print(f\\\"MAPE: {mape_rating:.4f}% (средняя абсолютная процентная ошибка)\\\")\n",
        "\n",
        "# Примеры предсказаний\n",
        "print(\\\"\\\\nПримеры предсказаний рейтингов:\\\")\n",
        "test_texts_rating = df_rating.loc[y_test_rating.index if hasattr(y_test_rating, 'index') else range(len(y_test_rating)), 'text'].values[:5]\n",
        "for i, text in enumerate(test_texts_rating[:5]):\n",
        "    print(f\\\"\\\\nТекст: {text}\\\")\n",
        "    print(f\\\"Истинный рейтинг: {y_test_rating[i]:.1f}/10\\\")\n",
        "    print(f\\\"Предсказанный рейтинг: {y_pred_rating[i]:.1f}/10\\\")\n",
        "    print(f\\\"Ошибка: {abs(y_test_rating[i] - y_pred_rating[i]):.2f} баллов\\\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Мультиклассовая классификация (3 класса: положительная, отрицательная, нейтральная)\n",
        "# One-hot encoding для мультиклассовой классификации\n",
        "y_train_sent_onehot = keras.utils.to_categorical(y_train_sent, num_classes=3)\n",
        "y_test_sent_onehot = keras.utils.to_categorical(y_test_sent, num_classes=3)\n",
        "\n",
        "print(f\\\"Классы: {np.unique(y_train_sent)}\\\")\n",
        "print(f\\\"Форма y_train_onehot: {y_train_sent_onehot.shape}\\\")\n",
        "\n",
        "# Модель для мультиклассовой классификации тональности\n",
        "model_sentiment_multi = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_sent_scaled.shape[1],)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(3, activation='softmax')  # Softmax для мультиклассовой классификации\n",
        "])\n",
        "\n",
        "model_sentiment_multi.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # Categorical cross-entropy для мультиклассовой\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stopping_sent_multi = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Обучение\n",
        "history_sent_multi = model_sentiment_multi.fit(\n",
        "    X_train_sent_scaled, y_train_sent_onehot,\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping_sent_multi],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Предсказания\n",
        "y_pred_proba_sent_multi = model_sentiment_multi.predict(X_test_sent_scaled)\n",
        "y_pred_sent_multi = np.argmax(y_pred_proba_sent_multi, axis=1)\n",
        "\n",
        "# Метрики (для мультиклассовой используем average='weighted' или 'macro')\n",
        "print(\\\"\\\\nМетрики для анализа тональности (мультиклассовая классификация):\\\")\n",
        "print(f\\\"F1-score (weighted): {f1_score(y_test_sent, y_pred_sent_multi, average='weighted'):.4f}\\\")\n",
        "print(f\\\"Precision (weighted): {precision_score(y_test_sent, y_pred_sent_multi, average='weighted'):.4f}\\\")\n",
        "print(f\\\"Recall (weighted): {recall_score(y_test_sent, y_pred_sent_multi, average='weighted'):.4f}\\\")\n",
        "\n",
        "# Примеры предсказаний\n",
        "sentiment_labels = {0: 'Отрицательная', 1: 'Положительная', 2: 'Нейтральная'}\n",
        "print(\\\"\\\\nПримеры предсказаний:\\\")\n",
        "test_texts_multi = df_sentiment.loc[y_test_sent.index if hasattr(y_test_sent, 'index') else range(len(y_test_sent)), 'text'].values[:5]\n",
        "for i, text in enumerate(test_texts_multi[:5]):\n",
        "    print(f\\\"\\\\nТекст: {text}\\\")\n",
        "    print(f\\\"Истинная тональность: {sentiment_labels[y_test_sent[i]]}\\\")\n",
        "    print(f\\\"Предсказанная тональность: {sentiment_labels[y_pred_sent_multi[i]]}\\\")\n",
        "    print(f\\\"Вероятности: {dict(zip(['Отрицательная', 'Положительная', 'Нейтральная'], y_pred_proba_sent_multi[i]))}\\\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Генерация данных для классификации (общие примеры)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification, make_regression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import (\n",
        "    f1_score, precision_score, recall_score,\n",
        "    mean_absolute_error, mean_squared_error\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Keras для примеров\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Генерация данных для классификации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Генерация сбалансированной выборки для бинарной классификации\n",
        "X_binary, y_binary = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=20,\n",
        "    n_informative=15,\n",
        "    n_redundant=5,\n",
        "    n_classes=2,\n",
        "    n_clusters_per_class=1,\n",
        "    random_state=42,\n",
        "    class_sep=1.0\n",
        ")\n",
        "\n",
        "# Разделение на train/test\n",
        "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(\n",
        "    X_binary, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
        ")\n",
        "\n",
        "# Нормализация данных\n",
        "scaler_bin = StandardScaler()\n",
        "X_train_bin_scaled = scaler_bin.fit_transform(X_train_bin)\n",
        "X_test_bin_scaled = scaler_bin.transform(X_test_bin)\n",
        "\n",
        "print(f\"Размер обучающей выборки: {X_train_bin_scaled.shape}\")\n",
        "print(f\"Размер тестовой выборки: {X_test_bin_scaled.shape}\")\n",
        "print(f\"Классы: {np.unique(y_train_bin)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Пример 1: Бинарная классификация с Keras (базовая модель)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создание модели\n",
        "model_binary = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_bin_scaled.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Бинарная классификация\n",
        "])\n",
        "\n",
        "# Компиляция модели\n",
        "model_binary.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',  # Logloss для бинарной классификации\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Обучение\n",
        "history_binary = model_binary.fit(\n",
        "    X_train_bin_scaled, y_train_bin,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Предсказания\n",
        "y_pred_binary = (model_binary.predict(X_test_bin_scaled) > 0.5).astype(int)\n",
        "y_pred_proba_binary = model_binary.predict(X_test_bin_scaled)\n",
        "\n",
        "# Метрики\n",
        "print(\"\\nМетрики для бинарной классификации:\")\n",
        "print(f\"F1-score: {f1_score(y_test_bin, y_pred_binary):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_bin, y_pred_binary):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_bin, y_pred_binary):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Пример 2: Бинарная классификация с Dropout и Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создание модели с dropout\n",
        "model_binary_dropout = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_bin_scaled.shape[1],)),\n",
        "    layers.Dropout(0.3),  # Dropout с вероятностью 0.3\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.2),  # Dropout с вероятностью 0.2\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Компиляция\n",
        "model_binary_dropout.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Обучение с early stopping\n",
        "history_dropout = model_binary_dropout.fit(\n",
        "    X_train_bin_scaled, y_train_bin,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Предсказания\n",
        "y_pred_dropout = (model_binary_dropout.predict(X_test_bin_scaled) > 0.5).astype(int)\n",
        "\n",
        "# Метрики\n",
        "print(\"\\nМетрики с dropout и early stopping:\")\n",
        "print(f\"F1-score: {f1_score(y_test_bin, y_pred_dropout):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_bin, y_pred_dropout):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_bin, y_pred_dropout):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Пример 3: Мультиклассовая классификация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Генерация данных для мультиклассовой классификации\n",
        "X_multi, y_multi = make_classification(\n",
        "    n_samples=1500,\n",
        "    n_features=20,\n",
        "    n_informative=15,\n",
        "    n_redundant=5,\n",
        "    n_classes=3,  # 3 класса\n",
        "    n_clusters_per_class=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Разделение на train/test\n",
        "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
        "    X_multi, y_multi, test_size=0.2, random_state=42, stratify=y_multi\n",
        ")\n",
        "\n",
        "# Нормализация\n",
        "scaler_multi = StandardScaler()\n",
        "X_train_multi_scaled = scaler_multi.fit_transform(X_train_multi)\n",
        "X_test_multi_scaled = scaler_multi.transform(X_test_multi)\n",
        "\n",
        "# One-hot encoding для мультиклассовой классификации\n",
        "y_train_multi_onehot = keras.utils.to_categorical(y_train_multi, num_classes=3)\n",
        "y_test_multi_onehot = keras.utils.to_categorical(y_test_multi, num_classes=3)\n",
        "\n",
        "print(f\"Классы: {np.unique(y_train_multi)}\")\n",
        "print(f\"Форма y_train_onehot: {y_train_multi_onehot.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Модель для мультиклассовой классификации\n",
        "model_multi = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_multi_scaled.shape[1],)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(3, activation='softmax')  # Softmax для мультиклассовой классификации\n",
        "])\n",
        "\n",
        "# Компиляция\n",
        "model_multi.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # Categorical cross-entropy для мультиклассовой\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stopping_multi = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Обучение\n",
        "history_multi = model_multi.fit(\n",
        "    X_train_multi_scaled, y_train_multi_onehot,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping_multi],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Предсказания\n",
        "y_pred_proba_multi = model_multi.predict(X_test_multi_scaled)\n",
        "y_pred_multi = np.argmax(y_pred_proba_multi, axis=1)\n",
        "\n",
        "# Метрики (для мультиклассовой используем average='weighted' или 'macro')\n",
        "print(\"\\nМетрики для мультиклассовой классификации:\")\n",
        "print(f\"F1-score (weighted): {f1_score(y_test_multi, y_pred_multi, average='weighted'):.4f}\")\n",
        "print(f\"Precision (weighted): {precision_score(y_test_multi, y_pred_multi, average='weighted'):.4f}\")\n",
        "print(f\"Recall (weighted): {recall_score(y_test_multi, y_pred_multi, average='weighted'):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Пример 4: Регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Генерация данных для регрессии\n",
        "X_reg, y_reg = make_regression(\n",
        "    n_samples=1000,\n",
        "    n_features=20,\n",
        "    n_informative=15,\n",
        "    noise=10.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Разделение на train/test\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Нормализация\n",
        "scaler_reg = StandardScaler()\n",
        "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
        "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n",
        "\n",
        "# Нормализация целевой переменной\n",
        "y_scaler = StandardScaler()\n",
        "y_train_reg_scaled = y_scaler.fit_transform(y_train_reg.reshape(-1, 1)).flatten()\n",
        "y_test_reg_scaled = y_scaler.transform(y_test_reg.reshape(-1, 1)).flatten()\n",
        "\n",
        "print(f\"Размер обучающей выборки: {X_train_reg_scaled.shape}\")\n",
        "print(f\"Диапазон y_train: [{y_train_reg.min():.2f}, {y_train_reg.max():.2f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Модель для регрессии\n",
        "model_reg = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_reg_scaled.shape[1],)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(1)  # Один выход для регрессии (без активации)\n",
        "])\n",
        "\n",
        "# Компиляция\n",
        "model_reg.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',  # Mean Squared Error для регрессии\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stopping_reg = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Обучение\n",
        "history_reg = model_reg.fit(\n",
        "    X_train_reg_scaled, y_train_reg_scaled,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping_reg],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Предсказания (обратная нормализация)\n",
        "y_pred_reg_scaled = model_reg.predict(X_test_reg_scaled).flatten()\n",
        "y_pred_reg = y_scaler.inverse_transform(y_pred_reg_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Метрики для регрессии\n",
        "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
        "mape = np.mean(np.abs((y_test_reg - y_pred_reg) / y_test_reg)) * 100\n",
        "\n",
        "print(\"\\nМетрики для регрессии:\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAPE: {mape:.4f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Пример 5: Визуализация процесса обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# График loss по эпохам\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_binary.history['loss'], label='Train Loss')\n",
        "plt.plot(history_binary.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Binary Classification - Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_binary.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_binary.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Binary Classification - Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Пример 6: Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# K-Fold Cross-Validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = []\n",
        "\n",
        "for train_idx, val_idx in kfold.split(X_train_bin_scaled):\n",
        "    X_train_cv, X_val_cv = X_train_bin_scaled[train_idx], X_train_bin_scaled[val_idx]\n",
        "    y_train_cv, y_val_cv = y_train_bin[train_idx], y_train_bin[val_idx]\n",
        "    \n",
        "    # Создание и обучение модели\n",
        "    model_cv = keras.Sequential([\n",
        "        layers.Dense(64, activation='relu', input_shape=(X_train_bin_scaled.shape[1],)),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    model_cv.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    model_cv.fit(\n",
        "        X_train_cv, y_train_cv,\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        verbose=0\n",
        "    )\n",
        "    \n",
        "    # Оценка на валидационной выборке\n",
        "    y_pred_cv = (model_cv.predict(X_val_cv) > 0.5).astype(int)\n",
        "    score = f1_score(y_val_cv, y_pred_cv)\n",
        "    cv_scores.append(score)\n",
        "\n",
        "print(f\"\\nCross-Validation F1-scores: {cv_scores}\")\n",
        "print(f\"Mean CV F1-score: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Скелет для реализации вашей нейронной сети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    \"\"\"\n",
        "    Простая полносвязная нейронная сеть.\n",
        "    \n",
        "    Параметры:\n",
        "    ----------\n",
        "    layers : list\n",
        "        Список размеров слоев, например [64, 32, 1] для сети с двумя скрытыми слоями\n",
        "    activation : str\n",
        "        Функция активации ('relu', 'sigmoid', 'softmax')\n",
        "    dropout_rate : float\n",
        "        Вероятность dropout (0.0 - без dropout)\n",
        "    task_type : str\n",
        "        Тип задачи ('classification' или 'regression')\n",
        "    num_classes : int\n",
        "        Количество классов (для классификации)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, layers, activation='relu', dropout_rate=0.0, \n",
        "                 task_type='classification', num_classes=2):\n",
        "        # TODO: инициализировать веса, сохранить параметры\n",
        "        # Подсказка: используйте np.random.randn() для инициализации весов\n",
        "        # Подсказка: для весов используйте инициализацию Xavier или He\n",
        "        pass\n",
        "    \n",
        "    def _forward_pass(self, X):\n",
        "        \"\"\"\n",
        "        Прямой проход (forward pass) через сеть.\n",
        "        \n",
        "        Параметры:\n",
        "        ----------\n",
        "        X : numpy array\n",
        "            Входные данные\n",
        "        \n",
        "        Возвращает:\n",
        "        --------\n",
        "        activations : list\n",
        "            Список активаций для каждого слоя\n",
        "        \"\"\"\n",
        "        # TODO: реализовать forward pass\n",
        "        # Подсказка: для каждого слоя вычислить z = X @ W + b, затем активацию\n",
        "        # Подсказка: для dropout - умножить на маску во время обучения\n",
        "        pass\n",
        "    \n",
        "    def _backward_pass(self, X, y, activations):\n",
        "        \"\"\"\n",
        "        Обратный проход (backpropagation) для вычисления градиентов.\n",
        "        \n",
        "        Параметры:\n",
        "        ----------\n",
        "        X : numpy array\n",
        "            Входные данные\n",
        "        y : numpy array\n",
        "            Целевые значения\n",
        "        activations : list\n",
        "            Активации из forward pass\n",
        "        \n",
        "        Возвращает:\n",
        "        --------\n",
        "        gradients : dict\n",
        "            Словарь градиентов для весов и смещений\n",
        "        \"\"\"\n",
        "        # TODO: реализовать backpropagation\n",
        "        # Подсказка: начать с вычисления градиента функции потерь\n",
        "        # Подсказка: распространить градиент назад через слои\n",
        "        # Подсказка: использовать цепное правило (chain rule)\n",
        "        pass\n",
        "    \n",
        "    def _compute_loss(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Вычисляет функцию потерь.\n",
        "        \n",
        "        Параметры:\n",
        "        ----------\n",
        "        y_true : numpy array\n",
        "            Истинные значения\n",
        "        y_pred : numpy array\n",
        "            Предсказанные значения\n",
        "        \n",
        "        Возвращает:\n",
        "        --------\n",
        "        loss : float\n",
        "            Значение функции потерь\n",
        "        \"\"\"\n",
        "        # TODO: реализовать logloss для классификации\n",
        "        # Для бинарной классификации: -mean(y*log(y_pred) + (1-y)*log(1-y_pred))\n",
        "        # Для мультиклассовой: categorical cross-entropy\n",
        "        # Для регрессии: MSE или MAE\n",
        "        pass\n",
        "    \n",
        "    def fit(self, X, y, epochs=100, batch_size=32, learning_rate=0.01,\n",
        "            validation_data=None, early_stopping=False, patience=10):\n",
        "        \"\"\"\n",
        "        Обучает нейронную сеть.\n",
        "        \n",
        "        Параметры:\n",
        "        ----------\n",
        "        X : numpy array\n",
        "            Обучающие данные\n",
        "        y : numpy array\n",
        "            Целевые значения\n",
        "        epochs : int\n",
        "            Количество эпох\n",
        "        batch_size : int\n",
        "            Размер батча\n",
        "        learning_rate : float\n",
        "            Скорость обучения\n",
        "        validation_data : tuple\n",
        "            (X_val, y_val) для валидации\n",
        "        early_stopping : bool\n",
        "            Использовать ли early stopping\n",
        "        patience : int\n",
        "            Терпение для early stopping\n",
        "        \"\"\"\n",
        "        # TODO: реализовать обучение\n",
        "        # Подсказка: для каждой эпохи:\n",
        "        #   1. Разбить данные на батчи\n",
        "        #   2. Для каждого батча: forward pass -> backward pass -> обновление весов\n",
        "        #   3. Вычислить loss на валидации (если есть)\n",
        "        #   4. Проверить early stopping (если включен)\n",
        "        pass\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Предсказывает классы/значения.\n",
        "        \n",
        "        Параметры:\n",
        "        ----------\n",
        "        X : numpy array\n",
        "            Входные данные\n",
        "        \n",
        "        Возвращает:\n",
        "        --------\n",
        "        predictions : numpy array\n",
        "            Предсказанные классы или значения\n",
        "        \"\"\"\n",
        "        # TODO: реализовать предсказание\n",
        "        # Подсказка: выполнить forward pass (без dropout!)\n",
        "        # Подсказка: для классификации - argmax или порог 0.5\n",
        "        pass\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Предсказывает вероятности (только для классификации).\n",
        "        \n",
        "        Параметры:\n",
        "        ----------\n",
        "        X : numpy array\n",
        "            Входные данные\n",
        "        \n",
        "        Возвращает:\n",
        "        --------\n",
        "        probabilities : numpy array\n",
        "            Вероятности классов\n",
        "        \"\"\"\n",
        "        # TODO: реализовать предсказание вероятностей\n",
        "        # Подсказка: выполнить forward pass и вернуть выход последнего слоя\n",
        "        # (для бинарной - sigmoid, для мультиклассовой - softmax)\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Пример использования вашей реализации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Пример использования (после реализации)\n",
        "# nn = NeuralNetwork(\n",
        "#     layers=[64, 32, 1],\n",
        "#     activation='relu',\n",
        "#     dropout_rate=0.3,\n",
        "#     task_type='classification',\n",
        "#     num_classes=2\n",
        "# )\n",
        "# \n",
        "# nn.fit(\n",
        "#     X_train_bin_scaled, y_train_bin,\n",
        "#     epochs=100,\n",
        "#     batch_size=32,\n",
        "#     learning_rate=0.01,\n",
        "#     validation_data=(X_test_bin_scaled, y_test_bin),\n",
        "#     early_stopping=True,\n",
        "#     patience=10\n",
        "# )\n",
        "# \n",
        "# y_pred = nn.predict(X_test_bin_scaled)\n",
        "# y_proba = nn.predict_proba(X_test_bin_scaled)\n",
        "# \n",
        "# print(f\"F1-score: {f1_score(y_test_bin, y_pred):.4f}\")\n",
        "# print(f\"Precision: {precision_score(y_test_bin, y_pred):.4f}\")\n",
        "# print(f\"Recall: {recall_score(y_test_bin, y_pred):.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
